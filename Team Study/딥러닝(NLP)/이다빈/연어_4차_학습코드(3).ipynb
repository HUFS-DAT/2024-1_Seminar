{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZ7MkH1zPDCbSm/atokLrT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 한국어 언어모델 학습 및 다중과제 튜닝"],"metadata":{"id":"AwgCXqDHC4pI"}},{"cell_type":"markdown","source":["####KoGPT-2 기반의 챗봇 실습"],"metadata":{"id":"4fnHLVNBC7g7"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"So0F9E02Cz1M","executionInfo":{"status":"ok","timestamp":1712501642908,"user_tz":-540,"elapsed":29187,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"dbb3d47c-842b-445c-ce5a-26b653e1f297"},"outputs":[{"output_type":"stream","name":"stdout","text":["Detected operating system as Ubuntu/jammy.\n","Checking for curl...\n","Detected curl...\n","Checking for gpg...\n","Detected gpg...\n","Detected apt version as 2.4.12\n","Running apt-get update... done.\n","Installing apt-transport-https... done.\n","Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n","Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n","done.\n","Running apt-get update... done.\n","\n","The repository is setup! You can now install packages.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following packages will be upgraded:\n","  git-lfs\n","1 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 7,420 kB of archives.\n","After this operation, 6,051 kB of additional disk space will be used.\n","Get:1 https://packagecloud.io/github/git-lfs/ubuntu jammy/main amd64 git-lfs amd64 3.5.1 [7,420 kB]\n","Fetched 7,420 kB in 1s (10.6 MB/s)\n","(Reading database ... 121757 files and directories currently installed.)\n","Preparing to unpack .../git-lfs_3.5.1_amd64.deb ...\n","Unpacking git-lfs (3.5.1) over (3.0.2-1ubuntu0.2) ...\n","Setting up git-lfs (3.5.1) ...\n","Git LFS initialized.\n","Processing triggers for man-db (2.10.2-1) ...\n"]}],"source":["!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n","!apt-get install git-lfs"]},{"cell_type":"code","source":["!git lfs install\n","!git clone https://huggingface.co/taeminlee/kogpt2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYcanJ11DN7T","executionInfo":{"status":"ok","timestamp":1712501678605,"user_tz":-540,"elapsed":35702,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"21474b32-4836-43ba-8726-f5f797ae6e6e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Git LFS initialized.\n","Cloning into 'kogpt2'...\n","remote: Enumerating objects: 56, done.\u001b[K\n","remote: Total 56 (delta 0), reused 0 (delta 0), pack-reused 56\u001b[K\n","Unpacking objects: 100% (56/56), 1.53 MiB | 3.19 MiB/s, done.\n","Filtering content: 100% (3/3), 1.41 GiB | 42.32 MiB/s, done.\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1XtqAFEaDN43","executionInfo":{"status":"ok","timestamp":1712501701577,"user_tz":-540,"elapsed":21962,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"b39b1dcd-1974-41f1-d500-9f2e20216b8e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}]},{"cell_type":"code","source":["import torch\n","from tokenizers import SentencePieceBPETokenizer\n","from transformers import GPT2Config, GPT2LMHeadModel\n","\n","tokenizer = SentencePieceBPETokenizer(\"/content/kogpt2/vocab.json\", \"/content/kogpt2/merges.txt\")\n","\n","config = GPT2Config(vocab_size=50000)\n","model = GPT2LMHeadModel(config)\n","\n","model_dir = '/content/kogpt2/pytorch_model.bin'\n","\n","model.load_state_dict(torch.load(model_dir, map_location='cpu'), strict=False) # cuda 대신 cpu로"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0a9_gCGDN2R","executionInfo":{"status":"ok","timestamp":1712501721302,"user_tz":-540,"elapsed":19397,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"572d69b0-3a42-4786-e860-d2bf182e63b5"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_IncompatibleKeys(missing_keys=[], unexpected_keys=['transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.bias', 'transformer.h.11.attn.masked_bias'])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["tokenized_text = tokenizer.encode('이순신은 조선 중기의 무신이다.', add_special_tokens=True)\n","print(tokenized_text)\n","print(tokenized_text.tokens)\n","print(tokenized_text.ids)\n","# 토크나이저 테스트 해보고 잘 되는 것 확인"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeLRcS1xDNz7","executionInfo":{"status":"ok","timestamp":1712501721302,"user_tz":-540,"elapsed":18,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"cd18d2fe-b568-4dc1-dee3-bac04c48b0bb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['▁이순', '신은', '▁조선', '▁중기의', '▁무신', '이다', '.']\n","[10925, 6647, 1117, 40249, 39793, 128, 47440]\n"]}]},{"cell_type":"code","source":["import torch\n","torch.manual_seed(42)\n","\n","input_ids = torch.tensor(tokenizer.encode(\"이순신은\", add_special_tokens=True).ids).unsqueeze(0)\n","\n","output_sequences = model.generate(input_ids=input_ids, do_sample=True, max_length=100, num_return_sequences=3)\n","for generated_sequence in output_sequences:\n","    generated_sequence = generated_sequence.tolist()\n","    print(\"GENERATED SEQUENCE : {0}\".format(tokenizer.decode(generated_sequence, skip_special_tokens=True)))\n","\n","# 단어 생성도 잘되는 것 확인\n","\n","# 다음은 데이터셋을 준비"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pO0QxFeHDNxs","executionInfo":{"status":"ok","timestamp":1712501759430,"user_tz":-540,"elapsed":23836,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"94ea1b9e-2a0f-4485-883c-8656433cd94e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["GENERATED SEQUENCE : 이순신은 “그 동안 은녀로 계셨던 여러분과 함께 하고 싶었습니다.</s><s> 두 사람 모두 30년 이상의 긴 호흡을 맞춘 첫사랑이라고.</s><s> 이들은 서로의 마음을 확인하는 '의자놀이'를 하며 서로를 달랬다.</s><s> 두 사람은 \"내가 먼저 미안해 하는 것 같아 미안하다.</s><s> 하지만, 좋은 남자로 시작해 보자는 뜻에서 (유)남편의 제안을 받아들였으니 결혼해서 잘 살자는 바람\"이라고 말하며 진심 어린 소감을 전했다.</s>\n","GENERATED SEQUENCE : 이순신은 자신의 아들이자 동무인 최숙향(김향수 분)를 만나러 가지만 아들 최충헌의 죽음과 함께 동무들 앞에서 죽음을 맞이하게 된다.</s><s> 한재석 측 \"유리한 해명 불구 해명글 게재는 아냐\"</s><s> 사진퍼가기 이용안내</s><s> 배우 한재석이 연예계 대표 ‘남남갈등’의 원인을 밝혔다.</s><s> 그는 앞서 KBS 2FM 라디오 '오후의 발견(이하 '오후의 발견')'\n","GENERATED SEQUENCE : 이순신은 \"내가 나 때문에 내 아들을 잃은 건 아닐까?\"</s><s> 이 때문에 박 씨는 '오블리비'(오블리비언을 위한 몸값)를 받으려고 한 것으로 보였다.</s><s> 제작진은 \"그녀가 오블리비언을 통해 자신의 삶을 보았을 때 자신의 딸들이 어떤 삶을 산다고 믿었을까도 생각한다\"고 말했다.</s><s> \"오블리비언을 하면서 딸이 스스로 살면 되는 것 아닌가\"라며 안도의 한숨을 내쉰 박 씨는 \"딸의 이야기를 하면서\n"]}]},{"cell_type":"markdown","source":["### 데이터셋 준비\n","심리상담을 위한 챗봇 데이터로 만들어보자"],"metadata":{"id":"kMUKGed4Dy2Y"}},{"cell_type":"code","source":["!git clone https://github.com/songys/Chatbot_data.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msgRC42uDNvO","executionInfo":{"status":"ok","timestamp":1712501772984,"user_tz":-540,"elapsed":676,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"828f8cea-8d76-4025-e82e-d3774eb1b028"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Chatbot_data'...\n","remote: Enumerating objects: 69, done.\u001b[K\n","remote: Counting objects:   4% (1/21)\u001b[K\rremote: Counting objects:   9% (2/21)\u001b[K\rremote: Counting objects:  14% (3/21)\u001b[K\rremote: Counting objects:  19% (4/21)\u001b[K\rremote: Counting objects:  23% (5/21)\u001b[K\rremote: Counting objects:  28% (6/21)\u001b[K\rremote: Counting objects:  33% (7/21)\u001b[K\rremote: Counting objects:  38% (8/21)\u001b[K\rremote: Counting objects:  42% (9/21)\u001b[K\rremote: Counting objects:  47% (10/21)\u001b[K\rremote: Counting objects:  52% (11/21)\u001b[K\rremote: Counting objects:  57% (12/21)\u001b[K\rremote: Counting objects:  61% (13/21)\u001b[K\rremote: Counting objects:  66% (14/21)\u001b[K\rremote: Counting objects:  71% (15/21)\u001b[K\rremote: Counting objects:  76% (16/21)\u001b[K\rremote: Counting objects:  80% (17/21)\u001b[K\rremote: Counting objects:  85% (18/21)\u001b[K\rremote: Counting objects:  90% (19/21)\u001b[K\rremote: Counting objects:  95% (20/21)\u001b[K\rremote: Counting objects: 100% (21/21)\u001b[K\rremote: Counting objects: 100% (21/21), done.\u001b[K\n","remote: Compressing objects:   5% (1/17)\u001b[K\rremote: Compressing objects:  11% (2/17)\u001b[K\rremote: Compressing objects:  17% (3/17)\u001b[K\rremote: Compressing objects:  23% (4/17)\u001b[K\rremote: Compressing objects:  29% (5/17)\u001b[K\rremote: Compressing objects:  35% (6/17)\u001b[K\rremote: Compressing objects:  41% (7/17)\u001b[K\rremote: Compressing objects:  47% (8/17)\u001b[K\rremote: Compressing objects:  52% (9/17)\u001b[K\rremote: Compressing objects:  58% (10/17)\u001b[K\rremote: Compressing objects:  64% (11/17)\u001b[K\rremote: Compressing objects:  70% (12/17)\u001b[K\rremote: Compressing objects:  76% (13/17)\u001b[K\rremote: Compressing objects:  82% (14/17)\u001b[K\rremote: Compressing objects:  88% (15/17)\u001b[K\rremote: Compressing objects:  94% (16/17)\u001b[K\rremote: Compressing objects: 100% (17/17)\u001b[K\rremote: Compressing objects: 100% (17/17), done.\u001b[K\n","remote: Total 69 (delta 18), reused 4 (delta 4), pack-reused 48\u001b[K\n","Receiving objects: 100% (69/69), 398.65 KiB | 6.64 MiB/s, done.\n","Resolving deltas: 100% (35/35), done.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","data = pd.read_csv('/content/Chatbot_data/ChatbotData.csv')"],"metadata":{"id":"Tkd9fcfpDNsj","executionInfo":{"status":"ok","timestamp":1712501803548,"user_tz":-540,"elapsed":4,"user":{"displayName":"이다빈","userId":"05137797752462423239"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["data.head(10)\n","# Qeustion 과 Answer 가 singleton 으로 연결되어 있는 데이터를 확인할 수 있음"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"h4yohXyaDNpw","executionInfo":{"status":"ok","timestamp":1712501808387,"user_tz":-540,"elapsed":6,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"3b34f2e0-1b9d-4b8b-da67-2395a55a58a3"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         Q                   A  label\n","0                   12시 땡!          하루가 또 가네요.      0\n","1              1지망 학교 떨어졌어           위로해 드립니다.      0\n","2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n","3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n","4                  PPL 심하네          눈살이 찌푸려지죠.      0\n","5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n","6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n","7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n","8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n","9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"],"text/html":["\n","  <div id=\"df-3862ed7b-5f94-44b8-b939-d0f598bad755\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>SD카드 망가졌어</td>\n","      <td>다시 새로 사는 게 마음 편해요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>SD카드 안돼</td>\n","      <td>다시 새로 사는 게 마음 편해요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n","      <td>잘 모르고 있을 수도 있어요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n","      <td>시간을 정하고 해보세요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n","      <td>시간을 정하고 해보세요.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3862ed7b-5f94-44b8-b939-d0f598bad755')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3862ed7b-5f94-44b8-b939-d0f598bad755 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3862ed7b-5f94-44b8-b939-d0f598bad755');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-28e87ad4-5026-4107-b4c9-98f3ff73fd44\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28e87ad4-5026-4107-b4c9-98f3ff73fd44')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-28e87ad4-5026-4107-b4c9-98f3ff73fd44 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["added_special_token_num = tokenizer.add_special_tokens(['<s>', '</s>'])\n","print(added_special_token_num)\n","# tokenizer 에게 명시적으로 문장의 시작과 끝을 알려줌"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-3fNgttDNnr","executionInfo":{"status":"ok","timestamp":1712501829228,"user_tz":-540,"elapsed":4,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"4f33133b-636e-48bc-eb27-6e95c75b8b6f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]},{"cell_type":"markdown","source":["그리고 fine-tuning 을 하는 과정을 거칠 예정이기 때문에 나중에 special token 이 추가가 된다고 하면 반드시 모델도 resize 하는 과정이 필요함\n","\n","지금 task 에서는 특별한 다른 token 이 추가되지 않겠지만 만약 본인이 원하는 special token 이 추가가 된다면 반드시 추가된 token 이 몇개인지 기억해두고 나중에 모델을 resize 하는 과정을 필수로 필요로 함"],"metadata":{"id":"rfBk1nBsEGX3"}},{"cell_type":"code","source":["pad_id = tokenizer.token_to_id(\"<pad>\")\n","print(pad_id)\n","tokenizer.enable_padding(pad_id=pad_id, pad_token=\"<pad>\")\n","tokenizer.enable_truncation(max_length=128)\n","\n","# <pad> 토큰도 넣어주기\n","\n","# BertTokenizer 에서는 padding 이라는 옵션으로 padding 을 설정해줬다면 이 tokenizer 는 enable_padding 으로 설정할 수 있음\n","\n","# truncation 할 때도 enable_truncation 으로 max_length 가 몇개인지 명시적으로 알려줌으로써 truncation 과 padding 을 가능하게 만들어주게 됨"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TO73aFRsDNlJ","executionInfo":{"status":"ok","timestamp":1712501856380,"user_tz":-540,"elapsed":4,"user":{"displayName":"이다빈","userId":"05137797752462423239"}},"outputId":"9893a2a5-448c-4b7e-8a7f-91ccf07af08c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n"]}]},{"cell_type":"code","source":["class ChatDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenizer, file_path):\n","        self.data = []\n","        self.file_path = file_path\n","        self.tokenizer = tokenizer\n","\n","    def load_data(self):\n","        raw_data = pd.read_csv(self.file_path)\n","        train_data = '<s>'+raw_data['Q']+'</s>'+'<s>'+raw_data['A']+'</s>'\n","        #<s>안녕하세요</s><s> -> 네, 안녕하세요</s>\n","        tokenized_train_data = tokenizer.encode_batch(train_data)\n","        for single_data in tokenized_train_data:\n","            self.data.append(torch.tensor(single_data.ids).unsqueeze(0))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        item = self.data[index]\n","        return item\n","\n","\n","# 학습을 위한 데이터를 만들어줘야 하는데 이 과정은 GPT-2 에서 pre-training 을 위해 데이터를 만들어줬던거랑 똑같음\n","# load_data(), __get_item__() 함수를 구현함\n","# load_data() 는 실제로 dataset 에서 데이터를 load 하고 우리가 원하는대로 전처리가 이루어지도록 데이터를 수정하는 과정을 말함"],"metadata":{"id":"tm8Q-uI0DNip","executionInfo":{"status":"ok","timestamp":1712501885694,"user_tz":-540,"elapsed":318,"user":{"displayName":"이다빈","userId":"05137797752462423239"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["train_dataset = ChatDataset(tokenizer=tokenizer, file_path='/content/Chatbot_data/ChatbotData.csv')\n","train_dataset.load_data()\n","\n","# tokenizer 명시해주고 file_path 명시해 줌\n","# load_data() 하게 되면 전체 데이터들이 self.data 안에 저장됨"],"metadata":{"id":"5G-lBvIYDNgI","executionInfo":{"status":"ok","timestamp":1712502061606,"user_tz":-540,"elapsed":1210,"user":{"displayName":"이다빈","userId":"05137797752462423239"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","\n","# 그 다음엔 떠먹여주는 data loader 를 만들어줌\n","# train dataset 을 batch_size 4만큼 input 으로 넣어라 라고 만들어주게 됨"],"metadata":{"id":"JxtnvdTDDNdq","executionInfo":{"status":"ok","timestamp":1712502079848,"user_tz":-540,"elapsed":339,"user":{"displayName":"이다빈","userId":"05137797752462423239"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from transformers import AdamW\n","\n","optimizer = AdamW(model.parameters(), lr=1e-4, correct_bias=True)\n","\n","epochs = 3\n","\n","avg_loss = (0.0, 0.0)\n","for epoch in range(epochs):\n","    count=0\n","    for data in data_loader:\n","        optimizer.zero_grad()\n","        data = data.transpose(1,0)\n","        data = data.to('cpu')\n","        model = model.to('cpu')\n","\n","        outputs = model(data, labels=data)\n","        loss, logits = outputs[:2]\n","        loss = loss.to('cpu')\n","        loss.backward()\n","        avg_loss = (avg_loss[0] * 0.99 + loss, avg_loss[1] * 0.99 + 1.0)\n","        optimizer.step()\n","        if count % 200 == 0:\n","            print('epoch no.{0}  train ({1}/{2})  loss = {3:.5f}  avg_loss = {4:.5f}' . format(epoch, count, len(data_loader), loss, avg_loss[0] / avg_loss[1]))\n","        count += 1\n","\n","# 현재 예제는 torch 를 사용했음\n","# pre-training 에서 사용한 예제를 사용해도 똑같이 동작함\n","# 모델에 data 를 넣고 label 이 data 자체가 됨\n","# GPT-2 는 학습할 때 data input 을 한칸씩 넣어가면서 다음 토큰이 뭐가나오는지 그 확률이 최대가 되도록 학습이 됨"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dvroVv4SDNbc","outputId":"8683797a-00b6-467f-8b7b-f04cae0ea208"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch no.0  train (0/2956)  loss = 2.68319  avg_loss = 2.68319\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'chitchat_model.bin')\n","# 모델을 저장하면 우리가 만든 chatbot 모델이 저장됨"],"metadata":{"id":"KTlHiVJTDNZA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실제 inference 를 통해서 챗봇과 대화하는 task 를 해봐야 함\n","def encoding(text):\n","    text = '<s>'+text+'</s><s>'\n","    return torch.tensor(tokenizer.encode(text).ids).unsqueeze(0).to('cuda')\n","\n","def decoding(ids):\n","    return tokenizer.decode_batch(ids)\n","\n","tokenizer.no_padding()\n","tokenizer.no_truncation()\n","\n","e_s = tokenizer.token_to_id('</s>')\n","unk = tokenizer.token_to_id('<unk>')\n","\n","# encoding() 함수는 내가 입력한 text 에 대해 앞뒤로 bos, eos token 을 넣어주게 되고 그 다음에 생성을 해야하는 시점이 <s> 토큰으로 문장의 시작점을 알려준 것임\n","# 이 text 를 vocab_id 로 치환해주고 vocab_id 로 치환된 것이 모델의 input 으로 들어감\n","# 그럼 모델은 뒷부분에 생성된 단어들을 만들어낼거고 그걸 다시 decoding 함으로써 원래 정답을 알아낼 수 있음"],"metadata":{"id":"j9MWKmDLDNWf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_answer(input_sent):\n","    input_ids = encoding(input_sent)\n","\n","    sample_outputs = model.generate(\n","        input_ids,\n","        num_return_sequences=5,\n","        do_sample=True,\n","        max_length=128,\n","        top_k=50,\n","        top_p=0.95,\n","        eos_token_id=e_s,\n","        early_stopping=True,\n","        bad_words_ids=[[unk]]\n","    )\n","\n","    decoded_result = decoding(sample_outputs.tolist())\n","    for result in decoded_result:\n","        print(result)"],"metadata":{"id":"imSmGvf5DNS-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["우리가 정의한 sentence 를 vocab_id 로 바꿔주고 그걸 모델의 입력으로 넣어주고 예제를 5개 보기 위해 설정하고 그리고 Sampling 도 넣고 top_k, top_p 두가지 옵션도 다 넣었고 max_length 까지 지정해줌\n","그 다음에 생성을 멈추도록 하는 eos_token_id 까지 입력해줌\n","\n","여기에 추가로 bad_words_ids 라는 옵션이 추가로 나왔는데 가끔 <unk> 토큰을 생성할 수 있음\n","입력된 거에 대해서 적정한 Random Sampling 과 top_p, top_k 를 참고하다보니 <unk> 토큰이 등장할 수 있음\n","\n","그 때 <unk> 토큰이 등장하게 되면 다른것을 선택해라라고 bad_words_ids 를 등록해줄 수 있음\n","\n","여기에 배열형태로 넣게되면 그 token 들이 생성되지 않도록 피하는 과정이 generate 함수내에서 이뤄지게 됨\n","\n","그래서 생성된 output(vocab_ids)을 이걸 decoding 을 하고 반환하게 되면 채팅결과가 나오는 것임"],"metadata":{"id":"RziPchNEF3zl"}},{"cell_type":"markdown","source":["##### Test"],"metadata":{"id":"T60wGIv6GFhj"}},{"cell_type":"code","source":["get_answer('안녕?')"],"metadata":{"id":"iwRWmQXiDNQj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_answer('만나서 반가워.')"],"metadata":{"id":"5r8D035TGJNY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_answer('인공지능의 미래에 대해 어떻게 생각하세요?')"],"metadata":{"id":"ZFG6062yGJLI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_answer('여자친구 선물 추천해줘.')"],"metadata":{"id":"yqBx4MdsGJIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_answer('앞으로 인공지능이 어떻게 발전하게 될까요?')"],"metadata":{"id":"xcZyUbO3GNHv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_answer('이제 그만 수업 끝내자.')"],"metadata":{"id":"3s2AB6zLGNF0"},"execution_count":null,"outputs":[]}]}